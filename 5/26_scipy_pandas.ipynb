{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Python Fortgeschritten: SciPy und Pandas\n",
        "## Tag 5 - Notebook 26\n",
        "***\n",
        "In diesem Notebook wird behandelt:\n",
        "- Pandas Series\n",
        "- DataFrame-Grundlagen\n",
        "- Indizierung und Selektion\n",
        "- Fehlende Daten\n",
        "- Datenoperationen (Sortieren, Gruppieren, Aggregationen)\n",
        "- I/O-Operationen (CSV, Excel, JSON)\n",
        "- SciPy-Grundlagen\n",
        "***\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1 Pandas Grundlagen\n",
        "\n",
        "Pandas ist eine Bibliothek für Datenanalyse und -manipulation.\n",
        "\n",
        "### Was verwendet Pandas unter der Haube?\n",
        "\n",
        "- **NumPy-Arrays**: Pandas nutzt NumPy für effiziente numerische Operationen\n",
        "- **C-Extensions**: Viele Operationen sind in C implementiert für Performance\n",
        "- **Indizierung**: Effiziente Indizierungsstrukturen für schnellen Zugriff\n",
        "- **Speicherverwaltung**: Optimierte Speichernutzung durch NumPy-Arrays\n",
        "\n",
        "### Hauptdatenstrukturen\n",
        "\n",
        "- **Series**: Eindimensionale markierte Arrays (wie eine Spalte)\n",
        "- **DataFrame**: Zweidimensionale tabellarische Struktur (wie eine Tabelle)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Series erstellen\n",
        "series = pd.Series([1, 2, 3, 4, 5], name='Werte')\n",
        "print(f\"Series:\\n{series}\")\n",
        "print(f\"\\nIndex: {series.index}\")\n",
        "print(f\"Werte: {series.values}\")\n",
        "\n",
        "# Series mit benutzerdefiniertem Index\n",
        "series_custom = pd.Series([10, 20, 30], index=['a', 'b', 'c'])\n",
        "print(f\"\\nSeries mit Index:\\n{series_custom}\")\n",
        "\n",
        "# DataFrame erstellen\n",
        "data = {'Name': ['Alice', 'Bob', 'Charlie'], 'Age': [25, 30, 35]}\n",
        "df = pd.DataFrame(data)\n",
        "print(f\"\\nDataFrame:\\n{df}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2 DataFrame-Grundlagen und Indizierung\n",
        "\n",
        "### Indizierung und Selektion\n",
        "\n",
        "- **loc**: Label-basierte Indizierung (Zeilen- und Spaltennamen)\n",
        "- **iloc**: Integer-basierte Indizierung (Position)\n",
        "- **Direkte Spaltenauswahl**: `df['Spalte']` oder `df.Spalte`\n",
        "- **Bedingte Selektion**: `df[df['Spalte'] > Wert]`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataFrame mit Index erstellen\n",
        "df = pd.DataFrame({\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David'],\n",
        "    'Age': [25, 30, 35, 28],\n",
        "    'Salary': [50000, 60000, 70000, 55000]\n",
        "}, index=['A', 'B', 'C', 'D'])\n",
        "\n",
        "print(f\"DataFrame:\\n{df}\")\n",
        "\n",
        "# loc: Label-basierte Indizierung\n",
        "print(f\"\\nloc['A']:\\n{df.loc['A']}\")\n",
        "print(f\"\\nloc['A':'C', 'Name':'Age']:\\n{df.loc['A':'C', 'Name':'Age']}\")\n",
        "\n",
        "# iloc: Integer-basierte Indizierung\n",
        "print(f\"\\niloc[0]:\\n{df.iloc[0]}\")\n",
        "print(f\"\\niloc[0:2, 0:2]:\\n{df.iloc[0:2, 0:2]}\")\n",
        "\n",
        "# Spaltenauswahl\n",
        "print(f\"\\nSpalte 'Name':\\n{df['Name']}\")\n",
        "print(f\"\\nMehrere Spalten:\\n{df[['Name', 'Age']]}\")\n",
        "\n",
        "# Bedingte Selektion\n",
        "df_filtered = df[df['Age'] > 27]\n",
        "print(f\"\\nGefiltert (Age > 27):\\n{df_filtered}\")\n",
        "\n",
        "# Datentypen\n",
        "print(f\"\\nDatentypen:\\n{df.dtypes}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3 Fehlende Daten\n",
        "\n",
        "Pandas bietet Funktionen zum Umgang mit fehlenden Werten (NaN):\n",
        "- **isna() / isnull()**: Prüft auf fehlende Werte\n",
        "- **dropna()**: Entfernt Zeilen/Spalten mit fehlenden Werten\n",
        "- **fillna()**: Füllt fehlende Werte mit einem Wert oder Methode\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DataFrame mit fehlenden Werten\n",
        "df_missing = pd.DataFrame({\n",
        "    'A': [1, 2, np.nan, 4],\n",
        "    'B': [5, np.nan, 7, 8],\n",
        "    'C': [9, 10, 11, np.nan]\n",
        "})\n",
        "\n",
        "print(f\"DataFrame mit NaN:\\n{df_missing}\")\n",
        "\n",
        "# Fehlende Werte finden\n",
        "print(f\"\\nFehlende Werte:\\n{df_missing.isna()}\")\n",
        "\n",
        "# Zeilen mit fehlenden Werten entfernen\n",
        "df_dropped = df_missing.dropna()\n",
        "print(f\"\\nNach dropna():\\n{df_dropped}\")\n",
        "\n",
        "# Fehlende Werte füllen\n",
        "df_filled = df_missing.fillna(0)\n",
        "print(f\"\\nMit fillna(0):\\n{df_filled}\")\n",
        "\n",
        "# Mit Mittelwert füllen\n",
        "df_filled_mean = df_missing.fillna(df_missing.mean())\n",
        "print(f\"\\nMit Mittelwert gefüllt:\\n{df_filled_mean}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "jp-MarkdownHeadingCollapsed": true
      },
      "source": [
        "## 4 Datenoperationen\n",
        "\n",
        "Häufige Operationen:\n",
        "- **Sortieren**: `sort_values()`, `sort_index()`\n",
        "- **Gruppieren**: `groupby()` mit Aggregationen\n",
        "- **Aggregationen**: `sum()`, `mean()`, `max()`, `min()`, `count()`\n",
        "- **Zusammenführen**: `merge()`, `join()`, `concat()`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Daten aus CSV laden\n",
        "df_sales = pd.read_csv('../data/sales_data.csv')\n",
        "print(f\"Sales Data:\\n{df_sales.head()}\")\n",
        "\n",
        "# Sortieren\n",
        "df_sorted = df_sales.sort_values('Sales', ascending=False)\n",
        "print(f\"\\nSortiert nach Sales:\\n{df_sorted.head()}\")\n",
        "\n",
        "# Gruppieren und Aggregieren\n",
        "sales_by_category = df_sales.groupby('Category')['Sales'].sum()\n",
        "print(f\"\\nSales nach Kategorie:\\n{sales_by_category}\")\n",
        "\n",
        "# Mehrere Aggregationen\n",
        "sales_stats = df_sales.groupby('Category').agg({\n",
        "    'Sales': ['sum', 'mean', 'max'],\n",
        "    'Quantity': 'sum'\n",
        "})\n",
        "print(f\"\\nStatistiken nach Kategorie:\\n{sales_stats}\")\n",
        "\n",
        "# Zusammenführen (Merge)\n",
        "df1 = pd.DataFrame({'key': ['A', 'B', 'C'], 'value1': [1, 2, 3]})\n",
        "df2 = pd.DataFrame({'key': ['B', 'C', 'D'], 'value2': [4, 5, 6]})\n",
        "df_merged = pd.merge(df1, df2, on='key', how='inner')\n",
        "print(f\"\\nMerged:\\n{df_merged}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5 I/O-Operationen\n",
        "\n",
        "Pandas kann Daten aus verschiedenen Formaten lesen und schreiben:\n",
        "- **CSV**: `read_csv()`, `to_csv()`\n",
        "- **Excel**: `read_excel()`, `to_excel()`\n",
        "- **JSON**: `read_json()`, `to_json()`\n",
        "- **Andere**: Parquet, HDF5, SQL, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CSV lesen\n",
        "df_employees = pd.read_csv('../data/employee_data.csv')\n",
        "print(f\"Employees:\\n{df_employees}\")\n",
        "\n",
        "# CSV schreiben\n",
        "df_employees.to_csv('../data/employee_data_backup.csv', index=False)\n",
        "\n",
        "# JSON\n",
        "json_data = df_employees.head(3).to_json(orient='records')\n",
        "print(f\"\\nJSON:\\n{json_data}\")\n",
        "\n",
        "# Aus JSON lesen\n",
        "df_from_json = pd.read_json(json_data)\n",
        "print(f\"\\nAus JSON:\\n{df_from_json}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6 SciPy Grundlagen\n",
        "\n",
        "SciPy baut auf NumPy auf und bietet wissenschaftliche Funktionen:\n",
        "- **scipy.stats**: Statistische Funktionen und Verteilungen\n",
        "- **scipy.optimize**: Optimierungsalgorithmen\n",
        "- **scipy.integrate**: Numerische Integration\n",
        "- **scipy.linalg**: Lineare Algebra\n",
        "- **scipy.signal**: Signalverarbeitung\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scipy import stats\n",
        "from scipy import optimize\n",
        "from scipy import integrate\n",
        "import numpy as np\n",
        "\n",
        "# Statistik: Normalverteilung\n",
        "data = np.random.normal(100, 15, 1000)\n",
        "mean, std = stats.norm.fit(data)\n",
        "print(f\"Normalverteilung - Mittelwert: {mean:.2f}, Std: {std:.2f}\")\n",
        "\n",
        "# Statistik: t-Test\n",
        "sample1 = np.random.normal(100, 10, 50)\n",
        "sample2 = np.random.normal(105, 10, 50)\n",
        "t_stat, p_value = stats.ttest_ind(sample1, sample2)\n",
        "print(f\"\\nt-Test - Statistik: {t_stat:.2f}, p-Wert: {p_value:.4f}\")\n",
        "\n",
        "# Optimierung: Minimum finden\n",
        "def f(x):\n",
        "    return (x - 3)**2 + 5\n",
        "\n",
        "result = optimize.minimize(f, x0=0)\n",
        "print(f\"\\nOptimierung - Minimum bei x={result.x[0]:.2f}, f(x)={result.fun:.2f}\")\n",
        "\n",
        "# Integration\n",
        "result_int, error = integrate.quad(lambda x: x**2, 0, 2)\n",
        "print(f\"\\nIntegration von x² von 0 bis 2: {result_int:.4f} (Fehler: {error:.2e})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7 Aufgaben\n",
        "\n",
        "### Aufgabe (a): DataFrame-Erstellung und Grundoperationen\n",
        "\n",
        "Erstelle DataFrames und führe Grundoperationen durch:\n",
        "\n",
        "**Anforderungen:**\n",
        "- Lade `data/employee_data.csv` in einen DataFrame\n",
        "- Zeige die ersten 5 Zeilen, Info und Datentypen\n",
        "- Berechne das Durchschnittsgehalt nach Abteilung (Department)\n",
        "- Sortiere den DataFrame nach Gehalt (Salary) in absteigender Reihenfolge\n",
        "- Gib die Ergebnisse aus\n",
        "\n",
        "**Tipp:** Verwende `pd.read_csv()`, `.head()`, `.info()`, `.dtypes`, `.groupby()`, `.mean()` und `.sort_values()`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deine Lösung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aufgabe (b): Datenanalyse mit Pandas\n",
        "\n",
        "Analysiere Verkaufsdaten:\n",
        "\n",
        "**Anforderungen:**\n",
        "- Lade `data/sales_data.csv`\n",
        "- Gruppiere nach Category und berechne für jede Kategorie: Summe, Mittelwert und Anzahl der Sales\n",
        "- Finde das Produkt (Product) mit dem höchsten Umsatz (Sales)\n",
        "- Berechne den Gesamtumsatz pro Tag (Date)\n",
        "- Gib die Ergebnisse aus\n",
        "\n",
        "**Tipp:** Verwende `.groupby()` mit `.agg()` für mehrere Aggregationen. Verwende `.idxmax()` oder `.nlargest()` um das Produkt mit dem höchsten Umsatz zu finden."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deine Lösung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aufgabe (c): Fehlende Daten und Datenbereinigung\n",
        "\n",
        "Umgang mit fehlenden Daten:\n",
        "\n",
        "**Anforderungen:**\n",
        "- Erstelle einen DataFrame mit absichtlich fehlenden Werten (verwende `np.nan` für einige Zellen)\n",
        "- Identifiziere fehlende Werte mit `isna()` oder `isnull()`\n",
        "- Fülle fehlende Werte mit dem Mittelwert der jeweiligen Spalte\n",
        "- Entferne Zeilen, die mehr als 2 fehlende Werte haben\n",
        "- Zeige die Ergebnisse der Bereinigung (Anzahl der Zeilen vorher/nachher)\n",
        "\n",
        "**Tipp:** Verwende `.isna()`, `.fillna()`, `.dropna()` mit dem Parameter `thresh` für die Bedingung \"mehr als 2 fehlende Werte\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deine Lösung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Aufgabe (d): SciPy Statistik\n",
        "\n",
        "Verwende SciPy für statistische Analysen:\n",
        "\n",
        "**Anforderungen:**\n",
        "- Lade `data/measurements_data.csv`\n",
        "- Teile die Daten in zwei Zeiträume (z.B. erste Hälfte vs. zweite Hälfte)\n",
        "- Führe einen t-Test zwischen den Temperaturen der beiden Zeiträume durch\n",
        "- Berechne die Normalverteilungsparameter (Mittelwert, Standardabweichung) für die Temperature-Spalte\n",
        "- Gib die statistischen Ergebnisse aus\n",
        "\n",
        "**Tipp:** Verwende `scipy.stats.ttest_ind()` für den t-Test und `scipy.stats.norm.fit()` für die Normalverteilungsparameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Deine Lösung"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Lösungen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from scipy import stats\n",
        "import logging\n",
        "\n",
        "logging.basicConfig(level=logging.DEBUG, format='%(levelname)s: %(message)s')\n",
        "\n",
        "# Musterlösung (a)\n",
        "logging.debug(\"=== Aufgabe (a): DataFrame-Erstellung und Grundoperationen ===\")\n",
        "\n",
        "df_employees = pd.read_csv('../data/employee_data.csv')\n",
        "logging.debug(f\"\\nErste 5 Zeilen:\\n{df_employees.head()}\")\n",
        "logging.debug(f\"\\nInfo:\\n{df_employees.info()}\")\n",
        "logging.debug(f\"\\nDatentypen:\\n{df_employees.dtypes}\")\n",
        "\n",
        "avg_salary_by_dept = df_employees.groupby('Department')['Salary'].mean()\n",
        "logging.debug(f\"\\nDurchschnittsgehalt nach Abteilung:\\n{avg_salary_by_dept}\")\n",
        "\n",
        "df_sorted = df_employees.sort_values('Salary', ascending=False)\n",
        "logging.debug(f\"\\nSortiert nach Gehalt (absteigend):\\n{df_sorted[['Name', 'Department', 'Salary']]}\")\n",
        "\n",
        "# Musterlösung (b)\n",
        "logging.debug(\"\\n=== Aufgabe (b): Datenanalyse mit Pandas ===\")\n",
        "\n",
        "df_sales = pd.read_csv('../data/sales_data.csv')\n",
        "df_sales['Date'] = pd.to_datetime(df_sales['Date'])\n",
        "\n",
        "sales_by_category = df_sales.groupby('Category')['Sales'].agg(['sum', 'mean', 'count'])\n",
        "logging.debug(f\"\\nSales nach Category:\\n{sales_by_category}\")\n",
        "\n",
        "product_max_sales = df_sales.loc[df_sales['Sales'].idxmax(), 'Product']\n",
        "max_sales_value = df_sales['Sales'].max()\n",
        "logging.debug(f\"\\nProdukt mit höchstem Umsatz: {product_max_sales} ({max_sales_value})\")\n",
        "\n",
        "sales_by_date = df_sales.groupby('Date')['Sales'].sum()\n",
        "logging.debug(f\"\\nGesamtumsatz pro Tag:\\n{sales_by_date}\")\n",
        "\n",
        "# Musterlösung (c)\n",
        "logging.debug(\"\\n=== Aufgabe (c): Fehlende Daten und Datenbereinigung ===\")\n",
        "\n",
        "# DataFrame mit fehlenden Werten erstellen\n",
        "df_missing = pd.DataFrame({\n",
        "    'A': [1, 2, np.nan, 4, 5, np.nan],\n",
        "    'B': [5, np.nan, 7, 8, np.nan, 10],\n",
        "    'C': [9, 10, 11, np.nan, np.nan, np.nan],\n",
        "    'D': [1, 2, 3, 4, 5, 6]\n",
        "})\n",
        "\n",
        "logging.debug(f\"DataFrame mit fehlenden Werten:\\n{df_missing}\")\n",
        "logging.debug(f\"\\nFehlende Werte:\\n{df_missing.isna().sum()}\")\n",
        "\n",
        "rows_before = len(df_missing)\n",
        "df_filled = df_missing.fillna(df_missing.mean())\n",
        "logging.debug(f\"\\nNach fillna():\\n{df_filled}\")\n",
        "\n",
        "df_cleaned = df_missing.dropna(thresh=len(df_missing.columns) - 2)\n",
        "rows_after = len(df_cleaned)\n",
        "logging.debug(f\"\\nNach dropna() (mehr als 2 fehlende Werte):\\n{df_cleaned}\")\n",
        "logging.debug(f\"Zeilen vorher: {rows_before}, nachher: {rows_after}\")\n",
        "\n",
        "# Musterlösung (d)\n",
        "logging.debug(\"\\n=== Aufgabe (d): SciPy Statistik ===\")\n",
        "\n",
        "df_measurements = pd.read_csv('../data/measurements_data.csv')\n",
        "df_measurements['Timestamp'] = pd.to_datetime(df_measurements['Timestamp'])\n",
        "\n",
        "# Daten in zwei Hälften teilen\n",
        "midpoint = len(df_measurements) // 2\n",
        "temp_first_half = df_measurements['Temperature'].iloc[:midpoint]\n",
        "temp_second_half = df_measurements['Temperature'].iloc[midpoint:]\n",
        "\n",
        "# t-Test\n",
        "t_stat, p_value = stats.ttest_ind(temp_first_half, temp_second_half)\n",
        "logging.debug(f\"\\nt-Test zwischen beiden Zeiträumen:\")\n",
        "logging.debug(f\"  t-Statistik: {t_stat:.4f}\")\n",
        "logging.debug(f\"  p-Wert: {p_value:.4f}\")\n",
        "\n",
        "# Normalverteilungsparameter\n",
        "mean, std = stats.norm.fit(df_measurements['Temperature'])\n",
        "logging.debug(f\"\\nNormalverteilungsparameter für Temperature:\")\n",
        "logging.debug(f\"  Mittelwert: {mean:.2f}\")\n",
        "logging.debug(f\"  Standardabweichung: {std:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Fortgeschritten)",
      "language": "python",
      "name": "python_fortgeschritten"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
